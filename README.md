# A.R.G.O.S - Sistema Conversacional de Voz en Tiempo Real

<div align="center">
 <img src="https://img.shields.io/badge/A.R.G.O.S-v1.1-blue?style=for-the-badge&logo=robot" alt="A.R.G.O.S Version">
 <img src="https://img.shields.io/badge/Edge--Cloud-AI%20System-green?style=for-the-badge&logo=nvidia" alt="Edge-Cloud System">
 <br>
 <img src="https://img.shields.io/badge/Python-3.8+-3776ab?style=flat&logo=python&logoColor=white" alt="Python">
 <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white" alt="PyTorch">
 <img src="https://img.shields.io/badge/NVIDIA-TensorRT-76B900?style=flat&logo=nvidia&logoColor=white" alt="TensorRT">
 <img src="https://img.shields.io/badge/Raspberry%20Pi-4B+-A22846?style=flat&logo=raspberry-pi&logoColor=white" alt="Raspberry Pi">
 <img src="https://img.shields.io/badge/ğŸ¤—-HuggingFace-FFD21E?style=flat" alt="HuggingFace">
 <br>
 <img src="https://img.shields.io/github/license/yourusername/A.R.G.O.S?style=flat" alt="License">
 <img src="https://img.shields.io/github/stars/yourusername/A.R.G.O.S?style=flat&logo=github" alt="Stars">
 <img src="https://img.shields.io/github/issues/yourusername/A.R.G.O.S?style=flat&logo=github" alt="Issues">
 
 <h3>ğŸ¯ Sistema conversacional de inteligencia artificial con arquitectura distribuida edge-cloud para interacciÃ³n humano-mÃ¡quina de baja latencia</h3>
</div>

---

## ğŸ“‘ Tabla de Contenidos

- [ğŸ” IntroducciÃ³n](#-introducciÃ³n)
- [ğŸ¯ Contribuciones Principales](#-contribuciones-principales)
- [ğŸ—ï¸ Arquitectura Distribuida Edge-Cloud](#ï¸-arquitectura-distribuida-edge-cloud)
- [ğŸ§  Modelo Orpheus-TTS](#-modelo-orpheus-tts)
- [ğŸ”§ Framework Modular](#-framework-modular)
- [ğŸ“š Referencias](#-referencias)
- [ğŸ¤ Contribuir](#-contribuir)
- [ğŸ“œ Licencia](#-licencia)

---

## ğŸ” IntroducciÃ³n

Los sistemas conversacionales en tiempo real se estÃ¡n convirtiendo en una herramienta necesaria para las aplicaciones de interacciÃ³n humano-mÃ¡quina. Sin embargo, su adopciÃ³n enfrenta **limitaciones importantes**:

> ğŸ¢ **Acceso restringido**: Los sistemas de alto nivel suelen estar limitados a infraestructuras privadas de grandes empresas  
> â˜ï¸ **Latencia en la nube**: Las soluciones basadas exclusivamente en la nube introducen retardos significativos incompatibles con la fluidez conversacional  
> ğŸ“± **Limitaciones Edge**: Las implementaciones en dispositivos Edge se ven limitadas por sus recursos computacionales  
> ğŸ”— **Complejidad de integraciÃ³n**: Dificultad de integrar mÃºltiples modelos (reconocimiento de voz, detecciÃ³n de actividad vocal y sÃ­ntesis de voz) en un mismo flujo de procesamiento conversacional

Estas restricciones evidencian la **necesidad de marcos equilibrados** que combinen precisiÃ³n, eficiencia y accesibilidad de cÃ³digo abierto.

**A.R.G.O.S** presenta un sistema conversacional de voz en tiempo real que integra **cinco modelos especializados de inteligencia artificial** en una arquitectura distribuida edge-cloud para una interacciÃ³n humano-mÃ¡quina de baja latencia. El sistema permite un flujo conversacional natural mediante streaming bidireccional de audio y un control inteligente de micrÃ³fono.

---

## ğŸ¯ Contribuciones Principales

### ğŸ—ï¸ **(I) Arquitectura Distribuida Edge-Cloud**
DiseÃ±o de una arquitectura que integra cinco modelos de inteligencia artificial especializados:
- **VAD** (Voice Activity Detection)
- **ASR** (Automatic Speech Recognition) 
- **NLU** (Natural Language Understanding)
- **TTS** (Text-to-Speech)
- **Control de Audio**

Logrando una **interacciÃ³n conversacional de baja latencia** en tiempo real.

### ğŸ™ï¸ **(II) Modelo TTS Optimizado (Orpheus)**
AdaptaciÃ³n y fine-tuning del modelo TTS Orpheus para sÃ­ntesis de voz en **castellano**:
- âœ… **Dataset propio** especializado
- âš¡ **Optimizaciones NVIDIA TensorRT** en formato **FP8**
- ğŸ“‰ **ReducciÃ³n significativa** del tiempo de inferencia y consumo de memoria en GPU

### ğŸ”§ **(III) Framework Modular Open Source**
ImplementaciÃ³n de un framework modular disponible en **GitHub** y **HuggingFace**:
- ğŸ”„ **Intercambiable**: Permite sustituir o extender el LLM central
- ğŸ“ˆ **Escalable**: Adaptable segÃºn requerimientos (Ventas, Servicio tÃ©cnico, EducaciÃ³n)
- ğŸ› ï¸ **Personalizable**: Permite la customizaciÃ³n de agentes conversacionales

---

## ğŸ—ï¸ Arquitectura Distribuida Edge-Cloud

El sistema implementa una **arquitectura hÃ­brida** que distribuye la carga computacional entre dispositivos de borde y recursos en la nube, optimizando tanto la latencia como la eficiencia energÃ©tica.




### ğŸ“Š DistribuciÃ³n de Componentes

| **Componente** | **UbicaciÃ³n** | **JustificaciÃ³n** |
|----------------|---------------|-------------------|
| **ğŸ”Š VAD** | Edge | Reduce ancho de banda y latencia inicial |
| **ğŸ“ ASR** | Edge/Cloud | Balance entre recursos locales y precisiÃ³n |
| **ğŸ§  NLU + LLM** | Cloud | Requiere alta capacidad computacional |
| **ğŸ¯ TTS** | Cloud | Modelo optimizado con TensorRT FP8 |
| **ğŸ›ï¸ Control Audio** | Edge | Respuesta inmediata requerida |

---

## ğŸ§  Modelo Orpheus-TTS

**Orpheus** es una familia de modelos LLM de voz de Ãºltima generaciÃ³n considerados como el **"state of the art"** en la generaciÃ³n de voz con un nivel de habla humano.

### ğŸ”¬ Arquitectura TÃ©cnica

- **ğŸ—ï¸ Base**: Utiliza **Llama-3.2-1B** con modificaciones estructurales en su arquitectura
- **ğŸ”„ Procesamiento**: Tokens de texto y audio entrelazados en formato codificado **SNAC** (Codecs de Audio Neurales)
- **ğŸµ Salida**: Decoder que genera espectrograma de audio con datos completos en resoluciÃ³n de **24kHz**

### âš¡ Optimizaciones Implementadas

- **ğŸ‡ªğŸ‡¸ Fine-tuning para castellano** con dataset propio especializado
- **ğŸš€ OptimizaciÃ³n NVIDIA TensorRT** en formato **FP8** para reducir latencia
- **ğŸ“¡ Streaming de audio bidireccional** para interacciÃ³n en tiempo real
- **ğŸ›ï¸ Control inteligente de micrÃ³fono** con detecciÃ³n de actividad vocal

### ğŸ”„ Pipeline de Procesamiento
 - ğŸ¤ MicrÃ³fono â†’ ğŸ”Š VAD â†’ ğŸ“ ASR â†’ ğŸ§  NLU â†’ ğŸ¤– LLM â†’ ğŸ¯ TTS (Orpheus) â†’ ğŸ”ˆ Altavoces



El sistema procesa el audio de entrada detectando primero la **actividad vocal**, transcribe el **habla a texto**, procesa la **intenciÃ³n del usuario**, genera una **respuesta contextual** y finalmente sintetiza la respuesta en **audio natural** usando el modelo Orpheus optimizado.

---

## ğŸ”§ Framework Modular

La **arquitectura modular** de A.R.G.O.S permite:

### ğŸ”„ **Intercambio de Modelos**
- SustituciÃ³n del LLM central segÃºn la aplicaciÃ³n especÃ­fica
- Compatibilidad con mÃºltiples proveedores de IA

### ğŸ“ˆ **Escalabilidad**
- Soporte para mÃºltiples usuarios concurrentes
- DistribuciÃ³n de carga automÃ¡tica

### ğŸ¯ **PersonalizaciÃ³n de Agentes**
- **ğŸ’¼ Ventas**: Agentes especializados en comercializaciÃ³n
- **ğŸ› ï¸ Soporte tÃ©cnico**: ResoluciÃ³n de problemas especializados
- **ğŸ“š EducaciÃ³n**: Tutores virtuales adaptativos

### ğŸ”Œ **Extensibilidad**
- FÃ¡cil integraciÃ³n de nuevos componentes de IA
- API modular para desarrolladores terceros

---

## ğŸ“š Referencias

<div align="left">

**[1]** Sathish, V., Lin, H., Kamath, A. K., & Nyayachavadi, A. (2024). *LLeMpower: Understanding Disparities in the Control and Access of Large Language Models*. arXiv preprint arXiv:2404.09356.

**[2]** Leow, C. S., Hayakawa, T., Nishizaki, H., & Kitaoka, N. (2020). *Development of a Low-Latency and Real-Time Automatic Speech Recognition System*. University of Yamanashi. Retrieved from https://www.alps-lab.org/wp-content/uploads/2020/11/1570656914.pdf

**[3]** Wang, T., Guo, J., Zhang, B., Yang, G., & Li, D. (2025). *Deploying AI on Edge: Advancement and Challenges in Edge Intelligence*. Mathematics, 13(11), 1878.

**[4]** Shah, B., Jain, S., & Taqa, A. (2025). *Hybrid Cloud Architectures for Multi-Modal AI Systems*. International Journal of Scientific Research, 2455-6211.

**[5]** Anonymous. (2024). *An Initial Investigation of Language Adaptation for TTS Systems under Low-resource Scenarios*. arXiv preprint arXiv:2406.08911. Retrieved from https://arxiv.org/pdf/2406.08911

**[6]** NVIDIA Corporation. *TensorRT - High Performance Deep Learning Inference*. NVIDIA Developer. Retrieved from https://developer.nvidia.com/tensorrt

</div>

---

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Para contribuir:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

<div align="center">
  <strong>Desarrollado con â¤ï¸ para la comunidad de IA conversacional</strong>
  <br>
  <sub>Si este proyecto te resulta Ãºtil, considera darle una â­</sub>
</div>